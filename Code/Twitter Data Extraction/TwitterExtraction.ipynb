{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twitter in c:\\softwares\\anaconda3\\lib\\site-packages (1.18.0)\n",
      "Requirement already satisfied: tweepy in c:\\softwares\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\softwares\\anaconda3\\lib\\site-packages (from tweepy) (1.12.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\softwares\\anaconda3\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in c:\\softwares\\anaconda3\\lib\\site-packages (from tweepy) (2.22.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in c:\\softwares\\anaconda3\\lib\\site-packages (from tweepy) (1.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\softwares\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\softwares\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\softwares\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\softwares\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\softwares\\anaconda3\\lib\\site-packages (from requests>=2.11.1->tweepy) (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install twitter\n",
    "import twitter\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# App Auth\n",
    "consumer_key = 'roE8oouLX19kWXsa6oTcwgkY2'\n",
    "consumer_secret = 'NFcewJQRREqq6CPNyhlwm6Emh2ELvdYeU3M0RJqvgaLnzSTltb'\n",
    "access_key = '1317466770-Hh9VTreJOVPzwUE0kGsO9RRtlgzpIo6WzzAKWnH'\n",
    "access_secret = 'AEM9C2pOxli1H0Ca6npnQnwZiIsZqPTL9QhIGHaWJ6qlR'\n",
    "\n",
    "# Initialize API\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Search terms\n",
    "search_words = [\"#coronavirus\", \"#COVID19\", \"#CoronavirusOutbreak\"] \n",
    "date_since = \"2019-12-01\"\n",
    "\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\",\n",
    "              since=date_since,tweet_mode='extended', \n",
    "              include_rts=True).items(1000)\n",
    "\n",
    "tweets_arr = []\n",
    "\n",
    "# Iterate and print tweets\n",
    "for tweet in tweets:\n",
    "    tweets_arr.append(tweet._json)\n",
    "print(\"Done\")\n",
    "\n",
    "with open(\"CoronaTwitterData.json\", \"w+\") as output:\n",
    "    output.write(json.dumps(tweets_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# App Auth\n",
    "consumer_key = 'roE8oouLX19kWXsa6oTcwgkY2'\n",
    "consumer_secret = 'NFcewJQRREqq6CPNyhlwm6Emh2ELvdYeU3M0RJqvgaLnzSTltb'\n",
    "access_key = '1317466770-Hh9VTreJOVPzwUE0kGsO9RRtlgzpIo6WzzAKWnH'\n",
    "access_secret = 'AEM9C2pOxli1H0Ca6npnQnwZiIsZqPTL9QhIGHaWJ6qlR'\n",
    "\n",
    "# Initialize API\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Search terms\n",
    "search_words = [\"#wuhanvirus\"] \n",
    "date_since = \"2019-12-01\"\n",
    "\n",
    "\n",
    "# Collect tweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\",\n",
    "              since=date_since,tweet_mode='extended', \n",
    "              include_rts=True).items(1000)\n",
    "\n",
    "tweets_arr = []\n",
    "\n",
    "# Iterate and print tweets\n",
    "for tweet in tweets:\n",
    "    tweets_arr.append(tweet._json)\n",
    "print(\"Done\")\n",
    "\n",
    "with open(\"CoronaTwitterData1.json\", \"w+\") as output:\n",
    "    output.write(json.dumps(tweets_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# App Auth\n",
    "consumer_key = 'roE8oouLX19kWXsa6oTcwgkY2'\n",
    "consumer_secret = 'NFcewJQRREqq6CPNyhlwm6Emh2ELvdYeU3M0RJqvgaLnzSTltb'\n",
    "access_key = '1317466770-Hh9VTreJOVPzwUE0kGsO9RRtlgzpIo6WzzAKWnH'\n",
    "access_secret = 'AEM9C2pOxli1H0Ca6npnQnwZiIsZqPTL9QhIGHaWJ6qlR'\n",
    "\n",
    "# Initialize API\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Search terms\n",
    "search_words = [\"#wuhanvirus\",\"#coronavirus\", \"#COVID19\", \"#CoronavirusOutbreak\"] \n",
    "date_since = \"2019-12-01\"\n",
    "\n",
    "\n",
    "# Collect tweets\n",
    "for i in search_words:\n",
    "    tweets = tw.Cursor(api.search,\n",
    "    q=i,\n",
    "    lang=\"en\",\n",
    "    since=date_since,tweet_mode='extended', \n",
    "    include_rts=True).items(1000)\n",
    "\n",
    "tweets_arr = []\n",
    "\n",
    "# Iterate and print tweets\n",
    "for tweet in tweets:\n",
    "    tweets_arr.append(tweet._json)\n",
    "print(\"Done\")\n",
    "\n",
    "with open(\"CoronaTwitterData2.json\", \"w+\") as output:\n",
    "    output.write(json.dumps(tweets_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# App Auth\n",
    "consumer_key = 'roE8oouLX19kWXsa6oTcwgkY2'\n",
    "consumer_secret = 'NFcewJQRREqq6CPNyhlwm6Emh2ELvdYeU3M0RJqvgaLnzSTltb'\n",
    "access_key = '1317466770-Hh9VTreJOVPzwUE0kGsO9RRtlgzpIo6WzzAKWnH'\n",
    "access_secret = 'AEM9C2pOxli1H0Ca6npnQnwZiIsZqPTL9QhIGHaWJ6qlR'\n",
    "\n",
    "# Initialize API\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Search terms\n",
    "search_words = [\"#COVID-19\"] \n",
    "date_since = \"2019-12-01\"\n",
    "\n",
    "\n",
    "# Collect tweets\n",
    "for i in search_words:\n",
    "    tweets = tw.Cursor(api.search,\n",
    "    q=i,\n",
    "    lang=\"en\",\n",
    "    since=date_since,tweet_mode='extended', \n",
    "    include_rts=True).items(1000)\n",
    "\n",
    "tweets_arr = []\n",
    "\n",
    "# Iterate and print tweets\n",
    "for tweet in tweets:\n",
    "    tweets_arr.append(tweet._json)\n",
    "print(\"Done\")\n",
    "\n",
    "with open(\"CoronaTwitterData3.json\", \"w+\") as output:\n",
    "    output.write(json.dumps(tweets_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json (r'C:\\Users\\vatsa\\Documents\\NTU\\Subjects\\Sem 2\\Data Extraction\\Group Project\\CoronaTwitterData3.json')\n",
    "df.to_csv (r'C:\\Users\\vatsa\\Documents\\NTU\\Subjects\\Sem 2\\Data Extraction\\Group Project\\CoronaTwitterData31.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
